import spacy
from spacy.training import Example
from spacy.util import minibatch, compounding
import random
import json
from pathlib import Path
import argparse
from typing import List, Tuple, Dict
import re
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import threading
import sys
from io import StringIO


class SpacyFineTuner:
    """Classe pour faciliter le fine-tuning de mod√®les spaCy pour la NER"""
    
    def __init__(self, model_size: str = "sm", lang: str = "fr"):
        """
        Initialise le fine-tuner
        
        Args:
            model_size: Taille du mod√®le ("sm", "md", "lg")
            lang: Langue du mod√®le (par d√©faut "fr" pour fran√ßais)
        """
        self.model_size = model_size
        self.lang = lang
        self.model_name = f"{lang}_core_news_{model_size}"
        self.nlp = None
        self.training_data = []
        
    def load_base_model(self):
        """Charge le mod√®le spaCy de base"""
        try:
            self.nlp = spacy.load(self.model_name)
            print(f"‚úì Mod√®le {self.model_name} charg√© avec succ√®s")
        except OSError:
            print(f"‚ö† Le mod√®le {self.model_name} n'est pas install√©.")
            print(f"Installez-le avec: python -m spacy download {self.model_name}")
            raise
            
        # Ajouter le pipeline NER s'il n'existe pas
        if "ner" not in self.nlp.pipe_names:
            ner = self.nlp.add_pipe("ner", last=True)
        else:
            ner = self.nlp.get_pipe("ner")
            
        return ner
    
    def load_proper_names(self, filepath: str) -> List[str]:
        """
        Charge les noms propres depuis un fichier
        
        Args:
            filepath: Chemin vers le fichier de noms propres (un nom par ligne)
        
        Returns:
            Liste des noms propres
        """
        names = []
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                name = line.strip()
                if name:
                    names.append(name)
        
        print(f"‚úì {len(names)} noms propres charg√©s")
        return names
    
    def load_sentence_templates(self, filepath: str) -> List[str]:
        """
        Charge les phrases types depuis un fichier
        
        Args:
            filepath: Chemin vers le fichier de phrases types
        
        Returns:
            Liste des phrases types
        """
        templates = []
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                template = line.strip()
                if template:
                    templates.append(template)
        
        print(f"‚úì {len(templates)} phrases types charg√©es")
        return templates
    
    def generate_training_data(self, names: List[str], templates: List[str], 
                             samples_per_template: int = 5) -> List[Tuple[str, Dict]]:
        """
        G√©n√®re des donn√©es d'entra√Ænement en combinant noms et phrases types
        
        Args:
            names: Liste des noms propres
            templates: Liste des phrases types avec placeholders
            samples_per_template: Nombre d'√©chantillons √† g√©n√©rer par template
        
        Returns:
            Liste de tuples (texte, annotations)
        """
        training_examples = []
        
        for template in templates:
            # Compter le nombre de placeholders dans le template
            placeholders = re.findall(r'\{NOM\}', template)
            num_placeholders = len(placeholders)
            
            if num_placeholders == 0:
                continue
                
            # G√©n√©rer plusieurs exemples pour chaque template
            for _ in range(samples_per_template):
                # S√©lectionner al√©atoirement des noms
                selected_names = random.sample(names, min(num_placeholders, len(names)))
                
                # Remplacer les placeholders et cr√©er les annotations
                text = template
                entities = []
                offset = 0
                
                for i, name in enumerate(selected_names):
                    # Trouver la position du placeholder
                    placeholder_pos = text.find('{NOM}', offset)
                    if placeholder_pos == -1:
                        break
                        
                    # Remplacer le placeholder
                    text = text[:placeholder_pos] + name + text[placeholder_pos + 5:]
                    
                    # Ajouter l'annotation
                    start = placeholder_pos
                    end = placeholder_pos + len(name)
                    entities.append((start, end, "PER"))  # PER pour personne
                    
                    # Mettre √† jour l'offset pour la prochaine recherche
                    offset = end
                
                # Ajouter l'exemple aux donn√©es d'entra√Ænement
                training_examples.append((text, {"entities": entities}))
        
        print(f"‚úì {len(training_examples)} exemples d'entra√Ænement g√©n√©r√©s")
        return training_examples
    
    def prepare_training_data(self, examples: List[Tuple[str, Dict]]) -> List[Example]:
        """
        Pr√©pare les donn√©es pour l'entra√Ænement spaCy
        
        Args:
            examples: Liste de tuples (texte, annotations)
        
        Returns:
            Liste d'objets Example pour spaCy
        """
        training_examples = []
        
        for text, annotations in examples:
            doc = self.nlp.make_doc(text)
            example = Example.from_dict(doc, annotations)
            training_examples.append(example)
            
        return training_examples
    
    def train(self, training_examples: List[Example], n_iter: int = 30, 
              drop: float = 0.35, batch_size: int = 8):
        """
        Entra√Æne le mod√®le NER
        
        Args:
            training_examples: Donn√©es d'entra√Ænement
            n_iter: Nombre d'it√©rations
            drop: Taux de dropout
            batch_size: Taille des batches
        """
        # Obtenir le pipeline NER
        ner = self.nlp.get_pipe("ner")
        
        # Ajouter les labels
        for _, annotations in self.training_data:
            for ent in annotations.get("entities", []):
                ner.add_label(ent[2])
        
        # D√©sactiver les autres pipelines pendant l'entra√Ænement
        other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != "ner"]
        
        with self.nlp.disable_pipes(*other_pipes):
            optimizer = self.nlp.begin_training()
            
            print("\nüöÄ D√©but de l'entra√Ænement...")
            
            for iteration in range(n_iter):
                print(f"\nIt√©ration {iteration + 1}/{n_iter}")
                
                # M√©langer les donn√©es
                random.shuffle(training_examples)
                losses = {}
                
                # Cr√©er les batches
                batches = minibatch(training_examples, size=compounding(4.0, batch_size, 1.001))
                
                for batch in batches:
                    # Mettre √† jour le mod√®le
                    self.nlp.update(batch, sgd=optimizer, drop=drop, losses=losses)
                
                print(f"Perte NER: {losses.get('ner', 0):.4f}")
        
        print("\n‚úì Entra√Ænement termin√©!")
    
    def evaluate(self, test_examples: List[Tuple[str, Dict]]) -> Dict:
        """
        √âvalue le mod√®le sur des donn√©es de test
        
        Args:
            test_examples: Exemples de test
        
        Returns:
            M√©triques d'√©valuation
        """
        scorer = self.nlp.evaluate(self.prepare_training_data(test_examples))
        return scorer
    
    def save_model(self, output_dir: str):
        """
        Sauvegarde le mod√®le fine-tun√©
        
        Args:
            output_dir: R√©pertoire de sortie
        """
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # Mettre √† jour les m√©tadonn√©es du mod√®le avant de sauvegarder
        self.nlp.meta["name"] = f"custom_ner_{self.model_size}"
        self.nlp.meta["version"] = "1.0.0"
        self.nlp.meta["description"] = "Mod√®le spaCy fine-tun√© pour la reconnaissance de noms propres"
        self.nlp.meta["author"] = "SpacyFineTuner"
        self.nlp.meta["lang"] = self.lang  # Important pour √©viter l'erreur E054
        self.nlp.meta["pipeline"] = list(self.nlp.pipe_names)
        self.nlp.meta["labels"] = {
            "ner": list(self.nlp.get_pipe("ner").labels)
        }
        
        # Sauvegarder le mod√®le avec ses m√©tadonn√©es
        self.nlp.to_disk(output_path)
        print(f"\n‚úì Mod√®le sauvegard√© dans: {output_path}")
        
        # Cr√©er aussi un fichier config.cfg si n√©cessaire
        config_path = output_path / "config.cfg"
        if not config_path.exists():
            # √âcrire la configuration minimale
            self.nlp.config.to_disk(config_path)
    
    def test_model(self, test_texts: List[str]):
        """
        Teste le mod√®le sur quelques exemples
        
        Args:
            test_texts: Textes √† tester
        """
        print("\nüß™ Test du mod√®le:")
        print("-" * 50)
        
        for text in test_texts:
            doc = self.nlp(text)
            print(f"\nTexte: {text}")
            print("Entit√©s d√©tect√©es:")
            for ent in doc.ents:
                print(f"  - {ent.text} ({ent.label_})")


class SpacyFineTunerGUI:
    """Interface graphique pour le fine-tuning de mod√®les spaCy"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("SpaCy Fine-Tuner - Entra√Ænement NER")
        self.root.geometry("800x600")
        
        # Variables
        self.names_file = tk.StringVar()
        self.templates_file = tk.StringVar()
        self.output_dir = tk.StringVar(value="model_custom_ner")
        self.model_size = tk.StringVar(value="sm")
        self.iterations = tk.IntVar(value=30)
        self.samples_per_template = tk.IntVar(value=5)
        self.is_training = False
        
        self.setup_ui()
        
    def setup_ui(self):
        """Configure l'interface utilisateur"""
        # Frame principal
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Configuration des poids pour le redimensionnement
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        
        # Titre
        title = ttk.Label(main_frame, text="Fine-Tuning SpaCy pour la reconnaissance d'entit√©s", 
                         font=('Helvetica', 16, 'bold'))
        title.grid(row=0, column=0, columnspan=3, pady=10)
        
        # Section fichiers
        files_frame = ttk.LabelFrame(main_frame, text="Fichiers de donn√©es", padding="10")
        files_frame.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=10)
        files_frame.columnconfigure(1, weight=1)
        
        # Fichier noms propres
        ttk.Label(files_frame, text="Noms propres:").grid(row=0, column=0, sticky=tk.W, padx=5)
        ttk.Entry(files_frame, textvariable=self.names_file).grid(row=0, column=1, sticky=(tk.W, tk.E), padx=5)
        ttk.Button(files_frame, text="Parcourir", 
                  command=lambda: self.browse_file(self.names_file)).grid(row=0, column=2, padx=5)
        
        # Fichier phrases types
        ttk.Label(files_frame, text="Phrases types:").grid(row=1, column=0, sticky=tk.W, padx=5, pady=5)
        ttk.Entry(files_frame, textvariable=self.templates_file).grid(row=1, column=1, sticky=(tk.W, tk.E), padx=5)
        ttk.Button(files_frame, text="Parcourir", 
                  command=lambda: self.browse_file(self.templates_file)).grid(row=1, column=2, padx=5)
        
        # Section param√®tres
        params_frame = ttk.LabelFrame(main_frame, text="Param√®tres", padding="10")
        params_frame.grid(row=2, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=10)
        params_frame.columnconfigure(1, weight=1)
        params_frame.columnconfigure(3, weight=1)
        
        # Mod√®le
        ttk.Label(params_frame, text="Taille du mod√®le:").grid(row=0, column=0, sticky=tk.W, padx=5)
        model_combo = ttk.Combobox(params_frame, textvariable=self.model_size, 
                                  values=["sm", "md", "lg"], state="readonly", width=10)
        model_combo.grid(row=0, column=1, sticky=tk.W, padx=5)
        
        # It√©rations
        ttk.Label(params_frame, text="It√©rations:").grid(row=0, column=2, sticky=tk.W, padx=5)
        ttk.Spinbox(params_frame, from_=10, to=100, textvariable=self.iterations, 
                   width=10).grid(row=0, column=3, sticky=tk.W, padx=5)
        
        # √âchantillons par template
        ttk.Label(params_frame, text="√âchantillons/template:").grid(row=1, column=0, sticky=tk.W, padx=5, pady=5)
        ttk.Spinbox(params_frame, from_=1, to=20, textvariable=self.samples_per_template, 
                   width=10).grid(row=1, column=1, sticky=tk.W, padx=5)
        
        # R√©pertoire de sortie
        ttk.Label(params_frame, text="Dossier de sortie:").grid(row=1, column=2, sticky=tk.W, padx=5)
        ttk.Entry(params_frame, textvariable=self.output_dir, width=20).grid(row=1, column=3, sticky=(tk.W, tk.E), padx=5)
        
        # Boutons d'action
        action_frame = ttk.Frame(main_frame)
        action_frame.grid(row=3, column=0, columnspan=3, pady=10)
        
        self.train_button = ttk.Button(action_frame, text="Lancer l'entra√Ænement", 
                                      command=self.start_training, style='Accent.TButton')
        self.train_button.grid(row=0, column=0, padx=5)
        
        ttk.Button(action_frame, text="Tester le mod√®le", 
                  command=self.test_model).grid(row=0, column=1, padx=5)
        
        # Zone de log
        log_frame = ttk.LabelFrame(main_frame, text="Journal d'ex√©cution", padding="10")
        log_frame.grid(row=4, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=10)
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        main_frame.rowconfigure(4, weight=1)
        
        self.log_text = scrolledtext.ScrolledText(log_frame, height=10, wrap=tk.WORD)
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Barre de progression
        self.progress = ttk.Progressbar(main_frame, mode='indeterminate')
        self.progress.grid(row=5, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)
        
        # Style
        style = ttk.Style()
        style.configure('Accent.TButton', font=('Helvetica', 10, 'bold'))
        
    def browse_file(self, var):
        """Ouvre un dialogue pour s√©lectionner un fichier"""
        filename = filedialog.askopenfilename(
            title="S√©lectionner un fichier",
            filetypes=[("Fichiers texte", "*.txt"), ("Tous les fichiers", "*.*")]
        )
        if filename:
            var.set(filename)
    
    def log(self, message):
        """Ajoute un message au journal"""
        self.log_text.insert(tk.END, message + "\n")
        self.log_text.see(tk.END)
        self.root.update()
    
    def start_training(self):
        """Lance l'entra√Ænement dans un thread s√©par√©"""
        if self.is_training:
            messagebox.showwarning("Entra√Ænement en cours", 
                                 "Un entra√Ænement est d√©j√† en cours!")
            return
            
        # V√©rifier les fichiers
        if not self.names_file.get() or not self.templates_file.get():
            messagebox.showerror("Erreur", 
                               "Veuillez s√©lectionner les deux fichiers requis!")
            return
        
        # Lancer dans un thread
        self.is_training = True
        self.train_button.config(state='disabled')
        self.progress.start()
        
        thread = threading.Thread(target=self.run_training)
        thread.start()
    
    def run_training(self):
        """Ex√©cute l'entra√Ænement"""
        # Rediriger stdout vers le journal
        old_stdout = sys.stdout
        sys.stdout = TextRedirector(self.log)
        
        try:
            # Initialiser le fine-tuner
            self.log("Initialisation du fine-tuner...")
            tuner = SpacyFineTuner(model_size=self.model_size.get(), lang="fr")
            
            # Charger le mod√®le de base
            self.log("Chargement du mod√®le de base...")
            tuner.load_base_model()
            
            # Charger les donn√©es
            self.log("Chargement des donn√©es...")
            names = tuner.load_proper_names(self.names_file.get())
            templates = tuner.load_sentence_templates(self.templates_file.get())
            
            # G√©n√©rer les donn√©es d'entra√Ænement
            self.log("G√©n√©ration des donn√©es d'entra√Ænement...")
            training_data = tuner.generate_training_data(
                names, templates, self.samples_per_template.get()
            )
            tuner.training_data = training_data
            
            # Diviser en ensemble d'entra√Ænement et de test
            split_point = int(len(training_data) * 0.8)
            train_data = training_data[:split_point]
            test_data = training_data[split_point:]
            
            # Pr√©parer les donn√©es d'entra√Ænement
            self.log("Pr√©paration des donn√©es...")
            training_examples = tuner.prepare_training_data(train_data)
            
            # Entra√Æner le mod√®le
            tuner.train(training_examples, n_iter=self.iterations.get())
            
            # √âvaluer le mod√®le
            if test_data:
                self.log("\n√âvaluation du mod√®le...")
                scores = tuner.evaluate(test_data)
                self.log(f"Scores: {scores}")
            
            # Sauvegarder le mod√®le
            tuner.save_model(self.output_dir.get())
            
            # Tester le mod√®le
            test_texts = [
                "Marie Dupont travaille chez Microsoft.",
                "J'ai rencontr√© Pierre Martin hier au bureau.",
                "Le docteur Jean-Paul Rousseau est en consultation."
            ]
            tuner.test_model(test_texts)
            
            self.log("\n‚úÖ Entra√Ænement termin√© avec succ√®s!")
            messagebox.showinfo("Succ√®s", "L'entra√Ænement est termin√© avec succ√®s!")
            
        except Exception as e:
            self.log(f"\n‚ùå Erreur: {str(e)}")
            messagebox.showerror("Erreur", f"Une erreur s'est produite:\n{str(e)}")
        finally:
            # Restaurer stdout
            sys.stdout = old_stdout
            self.is_training = False
            self.train_button.config(state='normal')
            self.progress.stop()
    
    def test_model(self):
        """Teste un mod√®le existant"""
        # Demander quel mod√®le tester
        test_choice = messagebox.askyesno(
            "Tester un mod√®le",
            "Voulez-vous tester le mod√®le que vous venez d'entra√Æner?\n\n"
            "Oui = Mod√®le actuel\n"
            "Non = Choisir un autre mod√®le"
        )
        
        model_path = self.output_dir.get()
        
        if not test_choice:
            # Demander le chemin du mod√®le
            model_path = filedialog.askdirectory(
                title="S√©lectionner le dossier du mod√®le √† tester"
            )
            if not model_path:
                return
        
        # V√©rifier que le mod√®le existe
        if not Path(model_path).exists():
            messagebox.showerror("Erreur", f"Le dossier '{model_path}' n'existe pas!")
            return
            
        if not (Path(model_path) / "meta.json").exists():
            messagebox.showerror("Erreur", 
                               f"Aucun mod√®le valide trouv√© dans '{model_path}'!\n"
                               "Assurez-vous que le dossier contient un mod√®le spaCy.")
            return
            
        try:
            # Charger le mod√®le
            self.log(f"Chargement du mod√®le depuis: {model_path}")
            nlp = spacy.load(model_path)
            
            # Cr√©er la fen√™tre de test
            test_window = tk.Toplevel(self.root)
            test_window.title("Tester le mod√®le")
            test_window.geometry("600x500")
            
            # Informations sur le mod√®le
            info_frame = ttk.LabelFrame(test_window, text="Informations du mod√®le", padding="5")
            info_frame.pack(fill=tk.X, padx=10, pady=5)
            
            model_info = f"Mod√®le: {nlp.meta.get('name', 'N/A')}\n"
            model_info += f"Version: {nlp.meta.get('version', 'N/A')}\n"
            model_info += f"Langue: {nlp.meta.get('lang', 'N/A')}\n"
            model_info += f"Pipeline: {', '.join(nlp.pipe_names)}"
            
            ttk.Label(info_frame, text=model_info, font=('Courier', 10)).pack()
            
            # Zone de saisie
            ttk.Label(test_window, text="Entrez un texte √† analyser:", 
                     font=('Helvetica', 12)).pack(pady=10)
            
            text_input = scrolledtext.ScrolledText(test_window, height=5, width=60)
            text_input.pack(padx=10, pady=5)
            text_input.insert(tk.END, "Marie Dupont a envoy√© un email √† Pierre Martin.")
            
            # Zone de r√©sultats
            result_frame = ttk.LabelFrame(test_window, text="R√©sultats", padding="5")
            result_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)
            
            result_text = scrolledtext.ScrolledText(result_frame, height=10, width=60)
            result_text.pack(fill=tk.BOTH, expand=True)
            
            def analyze():
                text = text_input.get("1.0", tk.END).strip()
                doc = nlp(text)
                
                result_text.delete("1.0", tk.END)
                result_text.insert(tk.END, "Entit√©s d√©tect√©es:\n" + "="*50 + "\n\n")
                
                if doc.ents:
                    for ent in doc.ents:
                        result_text.insert(tk.END, f"üìå {ent.text}\n")
                        result_text.insert(tk.END, f"   Type: {ent.label_}\n")
                        result_text.insert(tk.END, f"   Position: caract√®res {ent.start_char}-{ent.end_char}\n")
                        result_text.insert(tk.END, f"   Contexte: ...{text[max(0, ent.start_char-20):ent.end_char+20]}...\n\n")
                else:
                    result_text.insert(tk.END, "‚ùå Aucune entit√© d√©tect√©e dans ce texte.")
                
                # Ajouter le texte annot√©
                result_text.insert(tk.END, "\nTexte annot√©:\n" + "="*50 + "\n")
                annotated_text = text
                offset = 0
                for ent in sorted(doc.ents, key=lambda x: x.start_char):
                    start = ent.start_char + offset
                    end = ent.end_char + offset
                    annotation = f"[{ent.text}|{ent.label_}]"
                    annotated_text = annotated_text[:start] + annotation + annotated_text[end:]
                    offset += len(annotation) - (end - start)
                
                result_text.insert(tk.END, annotated_text)
            
            # Boutons
            button_frame = ttk.Frame(test_window)
            button_frame.pack(pady=10)
            
            ttk.Button(button_frame, text="Analyser", command=analyze, 
                      style='Accent.TButton').pack(side=tk.LEFT, padx=5)
            
            # Exemples pr√©d√©finis
            def load_example(text):
                text_input.delete("1.0", tk.END)
                text_input.insert("1.0", text)
                analyze()
            
            examples = [
                "Sophie Bernard a rencontr√© Michel Girard hier.",
                "Le rapport de Fran√ßois Lefebvre doit √™tre valid√© par Catherine Rousseau.",
                "Jean-Pierre Martin et Isabelle Moreau participent √† la r√©union."
            ]
            
            example_menu = tk.Menu(test_window, tearoff=0)
            for ex in examples:
                example_menu.add_command(label=ex[:50] + "...", 
                                       command=lambda t=ex: load_example(t))
            
            example_button = ttk.Button(button_frame, text="Exemples ‚ñº")
            example_button.pack(side=tk.LEFT, padx=5)
            example_button.bind("<Button-1>", lambda e: example_menu.post(e.x_root, e.y_root))
            
            # Analyser automatiquement le texte par d√©faut
            analyze()
            
        except Exception as e:
            self.log(f"‚ùå Erreur lors du chargement du mod√®le: {str(e)}")
            messagebox.showerror("Erreur", f"Impossible de charger le mod√®le:\n{str(e)}")
    
    def run(self):
        """Lance l'interface graphique"""
        self.root.mainloop()


class TextRedirector:
    """Redirige la sortie texte vers le widget de log"""
    def __init__(self, text_widget_callback):
        self.callback = text_widget_callback
        
    def write(self, string):
        self.callback(string.rstrip())
        
    def flush(self):
        pass


def main():
    """Point d'entr√©e principal"""
    # Si des arguments sont pass√©s, utiliser le mode ligne de commande
    if len(sys.argv) > 1:
        parser = argparse.ArgumentParser(description="Fine-tuning de mod√®les spaCy pour la NER")
        parser.add_argument("--model-size", choices=["sm", "md", "lg"], default="sm",
                           help="Taille du mod√®le spaCy (sm, md, lg)")
        parser.add_argument("--lang", default="fr", help="Langue du mod√®le")
        parser.add_argument("--names-file", required=True, help="Fichier contenant les noms propres")
        parser.add_argument("--templates-file", required=True, help="Fichier contenant les phrases types")
        parser.add_argument("--output-dir", default="model_custom_ner", help="R√©pertoire de sortie")
        parser.add_argument("--iterations", type=int, default=30, help="Nombre d'it√©rations")
        parser.add_argument("--samples-per-template", type=int, default=5, 
                           help="Nombre d'√©chantillons par phrase type")
        
        args = parser.parse_args()
        
        # Code original en ligne de commande
        tuner = SpacyFineTuner(model_size=args.model_size, lang=args.lang)
        tuner.load_base_model()
        names = tuner.load_proper_names(args.names_file)
        templates = tuner.load_sentence_templates(args.templates_file)
        training_data = tuner.generate_training_data(names, templates, args.samples_per_template)
        tuner.training_data = training_data
        
        split_point = int(len(training_data) * 0.8)
        train_data = training_data[:split_point]
        test_data = training_data[split_point:]
        
        training_examples = tuner.prepare_training_data(train_data)
        tuner.train(training_examples, n_iter=args.iterations)
        
        if test_data:
            print("\nüìä √âvaluation du mod√®le...")
            scores = tuner.evaluate(test_data)
            print(f"Score NER: {scores}")
        
        tuner.save_model(args.output_dir)
        
        test_texts = [
            "Marie Dupont travaille chez Microsoft.",
            "J'ai rencontr√© Pierre Martin hier au bureau.",
            "Le docteur Jean-Paul Rousseau est en consultation."
        ]
        tuner.test_model(test_texts)
        
        print("\n‚úÖ Processus termin√© avec succ√®s!")
        print(f"\nPour utiliser le mod√®le dans une autre application:")
        print(f"nlp = spacy.load('{args.output_dir}')")
    else:
        # Lancer l'interface graphique
        app = SpacyFineTunerGUI()
        app.run()


if __name__ == "__main__":
    main()